# data
data:
  instruct_data: "/content/data/ultrachat_chunk_train.jsonl"
  data: ""
  eval_instruct_data: "/content/data/ultrachat_chunk_eval.jsonl"

# model
model_id_or_path: "/content/mistral_models"

lora:
  rank: 64

seq_len: 8192
batch_size: 16
num_microbatches: 8
max_steps: 300
wandb:
  project: finetuining-mistral-7b

optim:
  lr: 1.e-4
  weight_decay: 0.1
  pct_start: 0.05

# other

seed: 0
log_freq: 1
eval_freq: 300
no_eval: False
ckpt_freq: 300

# save only trained LoRA adapters. 
# Set to `False` to merge LoRA adapter into the base model 
# and save full fine-tuned model
save_adapters: True 

run_dir: "/content/test_ultra" # Fill